{"cells":[{"cell_type":"markdown","source":["Name   : **`feature_ae_loss_scorer`**\n","\n","Purpose: Compare all models with default hyperparameters (Uncontrolled Experiments with Defaults)"],"metadata":{"id":"Mu5pJbu0_afk"},"id":"Mu5pJbu0_afk"},{"cell_type":"markdown","metadata":{"id":"zyoNkYXSpAnL"},"source":["# ============== `Setup` ======================================"],"id":"zyoNkYXSpAnL"},{"cell_type":"markdown","source":["## **Environment**"],"metadata":{"id":"ezpdQmpDmtHb"},"id":"ezpdQmpDmtHb"},{"cell_type":"markdown","source":["### `Colab Default`"],"metadata":{"id":"ScCyV6Gx_3rs"},"id":"ScCyV6Gx_3rs"},{"cell_type":"code","source":["import platform\n","import sklearn\n","import tensorflow as tf\n","import tensorboard as tb\n","import importlib\n","import numpy as np\n","import pandas as pd\n","\n","def check_env_setup():\n","    ### Checking\n","    print(\"-------------------- Setup completed! --------------------\\n\")\n","    print(\"OS                   :\", platform.platform())\n","    print(\"Python Version       :\", platform.python_version())\n","    print(\"TensorFlow           :\", tf.__version__)\n","    print(\"TensorBoard:         :\", tb.__version__)\n","    print(\"NumPy                :\", np.__version__)\n","    print(\"Pandas               :\", pd.__version__)\n","    print(\"Scikit-learn         :\", sklearn.__version__)\n","    #print(\"Optuna               :\", optuna.__version__)\n","    #print(\"Optuna-Integration   :\", importlib.metadata.version('optuna-integration'))\n","\n","    try:\n","        pass\n","        #print(\"Optuna-Integration  :\", importlib.metadata.version('optuna-integration'))\n","    except:\n","        pass\n","        # print(\"optuna-integration: Not found\")\n","check_env_setup()\n","\n","## =============================\n","\n","# CPU / GPU\n","def check_cpu_gpu():\n","    if tf.test.gpu_device_name():\n","        print(f\"\\nGPU is available: {tf.test.gpu_device_name()}\")\n","    else:\n","        print(\"\\nGPU is not available. Ensure you selected GPU runtime in Colab.\")\n","\n","    # Explicitly set GPU usage for TensorFlow (optional but useful for control)\n","    physical_devices = tf.config.list_physical_devices(\"GPU\")\n","    if physical_devices:\n","        try:\n","            # Enable memory growth (prevents TensorFlow from allocating all GPU memory at once)\n","            for device in physical_devices:\n","                tf.config.experimental.set_memory_growth(device, True)\n","            print(\"Memory growth enabled for GPU.\")\n","        except RuntimeError as e:\n","            print(f\"Memory growth error: {e}\")\n","    else:\n","        print(\"No GPU devices found. Ensure GPU runtime is enabled in Colab.\")\n","check_cpu_gpu()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758842593761,"user_tz":-180,"elapsed":26,"user":{"displayName":"zee abate","userId":"01001629947511882888"}},"outputId":"b0e21bce-d1d7-4382-b232-a7aa4f8e68c1","id":"OCu2QFHE_3rt"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["-------------------- Setup completed! --------------------\n","\n","OS                   : Linux-6.6.97+-x86_64-with-glibc2.35\n","Python Version       : 3.12.11\n","TensorFlow           : 2.19.0\n","TensorBoard:         : 2.19.0\n","NumPy                : 2.0.2\n","Pandas               : 2.2.2\n","Scikit-learn         : 1.6.1\n","\n","GPU is not available. Ensure you selected GPU runtime in Colab.\n","No GPU devices found. Ensure GPU runtime is enabled in Colab.\n"]}],"id":"OCu2QFHE_3rt"},{"cell_type":"markdown","source":["EXPERIMENT:\n","\n","feawad      --> Python 3.6 environment\n","\n","devnet      --> Python 3.6 environment\n","\n","deepsad     --> Python 3.8 environment\n","\n","dagmm       --> Python 3.8 environment\n","\n","vae_feawad  --> Python 3.6 environment"],"metadata":{"id":"iH3PgpIn_3ru"},"id":"iH3PgpIn_3ru"},{"cell_type":"markdown","source":["---"],"metadata":{"id":"6ypxa-3f_3rv"},"id":"6ypxa-3f_3rv"},{"cell_type":"markdown","metadata":{"id":"cEawIvZLjm1r"},"source":["### `Import`"],"id":"cEawIvZLjm1r"},{"cell_type":"code","execution_count":1,"metadata":{"id":"ofC7RKn7CP-h","executionInfo":{"status":"ok","timestamp":1759184504172,"user_tz":-180,"elapsed":13528,"user":{"displayName":"zee abate","userId":"01001629947511882888"}}},"outputs":[],"source":["import os\n","import sys\n","import numpy as np\n","\n","import random\n","import subprocess\n","import pathlib\n","import importlib\n","import shutil\n","import pprint\n","import json\n","\n","import torch\n","import tensorflow as tf\n","\n","from copy import deepcopy\n","from datetime import datetime\n","from dotenv import load_dotenv"],"id":"ofC7RKn7CP-h"},{"cell_type":"markdown","source":["### `Global Seed`"],"metadata":{"id":"DIQPM6MeURkg"},"id":"DIQPM6MeURkg"},{"cell_type":"code","source":["\n","FRAMEWORK   = 'TENSORFLOW'   # Options: ['TENSORFLOW', 'PYTORCH']\n","GLOBAL_SEED = 42\n","\n","def set_global_seeds(seed = 42, framework = 'TENSORFLOW'):\n","\n","    ## PYTHON & NUMPY\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    random.seed(seed)\n","    np.random.seed(seed)\n","\n","    ## TENSORFLOW\n","    if framework.upper() == 'TENSORFLOW':\n","        tf.random.set_seed(seed)\n","        os.environ['TF_DETERMINISTIC_OPS']   = '1'\n","        os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n","\n","    ## PYTORCH\n","    elif framework.upper() == 'PYTORCH':\n","        torch.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","        torch.backends.cudnn.deterministic  = True\n","        torch.backends.cudnn.benchmark      = False\n","\n","    else: raise ValueError(f\"Unknown framework: {framework}\")\n","    print(f\"Global seed set to {seed} for {framework}\")\n","\n","## SEED\n","set_global_seeds(GLOBAL_SEED, FRAMEWORK)"],"metadata":{"id":"--hdaKlg_HCZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758842725080,"user_tz":-180,"elapsed":32,"user":{"displayName":"zee abate","userId":"01001629947511882888"}},"outputId":"2893dded-657e-4006-b48f-ed0aa49dc218"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Global seed set to 42 for TENSORFLOW\n"]}],"id":"--hdaKlg_HCZ"},{"cell_type":"markdown","source":["### `Mount`"],"metadata":{"id":"eyQtkTTXdV-5"},"id":"eyQtkTTXdV-5"},{"cell_type":"code","source":["### GOOGLE DRIVE\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","def connect_google_drive(force_mount = False):\n","    if not os.path.exists('/content/drive/MyDrive') or force_mount:\n","        from google.colab import drive\n","        # Try unmounting first to ensure a clean mount\n","        try:\n","            drive.flush_and_unmount()\n","            print('\\nAll changes made in this colab session should now be visible in Drive.')\n","        except ValueError:\n","            pass\n","\n","        if os.path.exists('/content/drive'):\n","            # !rm -rf /content/drive  # Remove the directory and its contents\n","            print(\"Removed existing '/content/drive' directory.\")\n","            print(\"'/content/drive' directory found, uncomment to remove & re-mount!!!\")\n","\n","        drive.mount('/content/drive', force_remount = True)\n","\n","    else:\n","        print(\"Google Drive already mounted.\")\n","connect_google_drive(force_mount = False)"],"metadata":{"id":"pyT1wd68c8Ys","executionInfo":{"status":"ok","timestamp":1759184524306,"user_tz":-180,"elapsed":20128,"user":{"displayName":"zee abate","userId":"01001629947511882888"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"579b6cd9-8667-454d-b04a-b1e00e02b4e4"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive not mounted, so nothing to flush and unmount.\n","\n","All changes made in this colab session should now be visible in Drive.\n","Mounted at /content/drive\n"]}],"id":"pyT1wd68c8Ys"},{"cell_type":"markdown","source":["## **Helpers**"],"metadata":{"id":"VoJnHp4fnRSw"},"id":"VoJnHp4fnRSw"},{"cell_type":"markdown","source":["### `Common Utils`"],"metadata":{"id":"D7wzqeNGi6Yr"},"id":"D7wzqeNGi6Yr"},{"cell_type":"code","source":["## JSON SERIALIZER\n","class NpEncoder(json.JSONEncoder):\n","    def default(self, obj):\n","        if isinstance(obj, np.bool_):\n","            return bool(obj)\n","        if isinstance(obj, (np.floating, np.complexfloating)):\n","            return float(obj)\n","        if isinstance(obj, np.integer):\n","            return int(obj)\n","        if isinstance(obj, np.ndarray):\n","            return obj.tolist()\n","        # if isinstance(obj, np.string_):\n","        if isinstance(obj, np.bytes_): # Changed np.string_ to np.bytes_\n","            return str(obj)\n","        if isinstance(obj, (datetime, date)):\n","            return obj.isoformat()\n","        if isinstance(obj, timedelta):\n","            return str(obj)\n","        if isinstance(obj, tf.keras.optimizers.Optimizer): # Handle Optimizer objects\n","            return obj.get_config() # Serialize the configuration instead of the object\n","        return super(NpEncoder, self).default(obj)"],"metadata":{"id":"Q9JQtKJvS4Oi"},"execution_count":null,"outputs":[],"id":"Q9JQtKJvS4Oi"},{"cell_type":"markdown","source":["### `Dev Utils`"],"metadata":{"id":"IGtGRqUdnRj_"},"id":"IGtGRqUdnRj_"},{"cell_type":"code","source":["######################################################################################################################################\n","if True: ##  FUNCTIONS  (DRIVE)\n","    def get_drive_helper_paths(\n","            dr_utils_dir_path = \"/content/drive/MyDrive/MSc_AAiT/project_setup_helper/utils\",\n","            path_configs_file    = \"drive_path_configs.json\"\n","        ):\n","        if not os.path.exists('/content/drive/MyDrive'): connect_google_drive(force_mount = False)\n","        drive_utils_file_path = os.path.join(dr_utils_dir_path, path_configs_file)\n","        with open(drive_utils_file_path, \"r\") as f:\n","            drive_paths_json = json.load(f)\n","        return drive_paths_json\n","    def drive_setup_helper_syspath(\n","            dr_setup_helper_path    = \"/content/drive/MyDrive/MSc_AAiT/project_setup_helper\",\n","            util_modules_dir        = None, ## \"utils\",\n","            util_module_name        = None  ## \"git_ssh_utils\", \"xxxxx\"\n","        ):\n","\n","        if not os.path.exists('/content/drive/MyDrive'): connect_google_drive(force_mount = False)\n","\n","        utils_path = os.path.join(dr_setup_helper_path, util_modules_dir) if util_modules_dir is not None else dr_setup_helper_path\n","        if not os.path.exists(utils_path): raise FileNotFoundError(f\"Path not found: {utils_path}\")\n","        if utils_path not in sys.path: sys.path.append(utils_path) ### Ensure path is in sys.path\n","        print(f\"Util modules path '{utils_path}' added to sys.path\")\n","\n","        ### Try importing\n","        module = None\n","        if util_module_name is not None:\n","            module = importlib.import_module(util_module_name)\n","            importlib.reload(module)\n","            print(f\"Imported {util_module_name} from {utils_path}\")\n","        return module\n","    def manage_gitssh_colab_github(\n","            project_envs,\n","            git_ssh_helper,\n","            start_ssh_session   = False,\n","            show_pub_key        = False,\n","            force_new_keys_gen  = False\n","        ):\n","\n","        if not project_envs:   raise ValueError(\"Enviroment variable key-pair 'project_envs' is not defined!\")\n","        if not git_ssh_helper: raise ValueError(\"Git & SSH helper script 'git_ssh_helper' is not defined!\")\n","        if not start_ssh_session and not show_pub_key and not force_new_keys_gen:\n","            raise ValueError(\"At least one of the following flags must be True: ['start_ssh_session', 'show_pub_key', 'force_new_keys_gen']\")\n","\n","        # ============================================================\n","        print(f\"\\n{'=' * 20} Git global config (In colab) {'=' * 20}\")\n","        git_ssh_helper.git_global_user_config(\n","            project_envs.GIT_USER_NAME,\n","            project_envs.GIT_USER_EMAIL,\n","            user_scope  = '--global',\n","            verbose     = project_envs.VERBOSE\n","        )\n","\n","        # ================================================================================================================\n","        if project_envs.SSH_FORCE_GENERATION: force_new_keys_gen = project_envs.SSH_FORCE_GENERATION\n","\n","        if force_new_keys_gen:  print(f\"\\n{'=' * 20} New ssh key-pair generation {'=' * 20}\")\n","        elif show_pub_key:      print(f\"\\n{'=' * 20} Show ssh public key {'=' * 20}\")\n","        elif start_ssh_session: print(f\"\\n{'=' * 20} Start new ssh session (colab-github) {'=' * 20}\")\n","\n","        if force_new_keys_gen or show_pub_key: ### TO FORCE QUIQUE RE/GENERATE KEY-PAIR (WITHOUT GOING & SET/CONFIG in 'project_envs')\n","            git_ssh_helper.setup_ssh_colab_github(\n","                ssh_priv_key_path   = project_envs.SSH_KEY_STORE_PATH,\n","                git_user_email      = project_envs.GIT_USER_EMAIL,\n","                ssh_added_to_github = False,                        ## QUIQUE MANUAL SETTING  (WITHOUT SETTING/CONFIG IN 'proj_env')\n","                force_generate_keys = force_new_keys_gen,           ## QUIQUE MANUAL SETTING\n","                verbose             = project_envs.VERBOSE\n","            )\n","        elif start_ssh_session:                ### TO START NEW-SESSION (AND OR BASED 'project_envs' SETTING)\n","            git_ssh_helper.setup_ssh_colab_github(\n","                ssh_priv_key_path   = project_envs.SSH_KEY_STORE_PATH,\n","                git_user_email      = project_envs.GIT_USER_EMAIL,\n","                ssh_added_to_github = project_envs.SSH_ADDED_TO_GITHUB,  # 'False': to display (get/copy) stored Public-Key without session setup.\n","                force_generate_keys = project_envs.SSH_FORCE_GENERATION, # 'True':  to delete & regenerate Kay-pairs.\n","                verbose             = project_envs.VERBOSE\n","            )\n","        else: raise ValueError(f\"Invalid args!\")\n","\n","    def clone_repo_from_github(    ### First-time push of scaffold (Drive --> GitHub).\n","            project_envs,\n","            git_ssh_helper,\n","            colab_repo_path     = None,     # Path to the cloned GitHub repo in Colab\n","            verbose             = None,\n","            force_clone         = False,\n","        ):\n","\n","        m_colab_repo_path = colab_repo_path or os.path.join(project_envs.COLAB_HOME_PATH, project_envs.GITHUB_REPO_NAME) ## Path to the cloned GitHub repo in Colab\n","        m_verbose         = verbose         or project_envs.VERBOSE\n","\n","        if force_clone:\n","            if os.path.exists(m_colab_repo_path):\n","                print(f\"\\n=> *** Repo is cloned before & found at: {m_colab_repo_path}, removing .... ***\")\n","                shutil.rmtree(m_colab_repo_path)\n","                if os.path.exists(m_colab_repo_path): raise RuntimeError(f\"Failed to remove existing repo: {m_colab_repo_path}\")\n","            else: print(f\"\\n=> Repo is not cloned before, procede to cloning ...\")\n","        else:\n","            if os.path.exists(m_colab_repo_path):\n","                print(f\"\\n=> **** Repo is cloned before & 'force cloning' is not set. Existed repo found at: {m_colab_repo_path} ***\")\n","                return\n","\n","        # ==================================================================================================\n","        if False: print(f\"\\n{'=' * 20} Resolve gitHub repo url {'=' * 20}\")\n","        github_repo_url =  git_ssh_helper.get_github_repo_url( ### Authenticated Template Repo URL\n","            gh_repo_auth = project_envs.GITHUB_REPO_AUTH,         ## Options: [None, 'PAT', 'SSH'] # If gh_repo_auth == None: 'GitHub Repo Auth is Anonymous (https based Un-auth access)'\n","            gh_pat_token = project_envs.GITHUB_PAT_TOKEN,         ## GitHub 'Personal Access Token (PAT)':\n","            gh_username  = project_envs.GITHUB_USERNAME,\n","            gh_repo_name = project_envs.GITHUB_REPO_NAME          ## GITHUB_TEMPLATE_NAME     # GITHUB_REPO_NAME    ##\"anomaly-detection-msc-thesis\",   # msc-thesis-template\n","        )\n","        print(f\"\\n=> github_repo_url: {github_repo_url}\")\n","\n","        # ==================================================================================================\n","        print(f\"\\n{'=' * 20} Clone the repository (github --> colab) {'=' * 20}\")\n","        git_ssh_helper.clone_github_repo(\n","            gh_repo_url     = github_repo_url,\n","            gh_repo_name    = project_envs.GITHUB_REPO_NAME,\n","            local_root_dir  = project_envs.COLAB_HOME_PATH,\n","            ssh_temp_dir    = project_envs.SSH_SESS_PATH,\n","            explicit_ssh    = project_envs.SSH_EXPLICIT_CLONE,\n","            force_clone     = project_envs.GITHUB_FORCE_CLONE,\n","            verbose         = m_verbose\n","        )\n","\n","        os.chdir(m_colab_repo_path)\n","        if m_verbose:\n","            git_config_path = os.path.join(m_colab_repo_path, \".git\")\n","            print(\"\\n=> Cloned repo is git-repo (.git file):\")\n","            !ls -al {git_config_path}\n","        if not git_ssh_helper.is_git_repo(): raise EnvironmentError(f\"{m_colab_repo_path} is not a Git repository ('.git' missing)\")\n","        print(f\"\\n=> Current working directory (cloned repo): {os.getcwd()}\")\n","\n","        return github_repo_url\n","    def git_remote_and_branch_config(\n","            project_envs,\n","            git_ssh_helper,\n","            github_repo_url,\n","            branch_name         = \"main\",\n","            br_remote_name      = \"origin\",\n","            base_branch         = \"main\",       # Base branch if creating a new branch\n","            auto_commit         = True,\n","            auto_push           = True,\n","            verbose             = None,\n","            commit_msg          = \"Update repo files\"\n","        ):\n","\n","\n","        verbose = verbose or project_envs.VERBOSE\n","        print(f\"\\n{'=' * 20} Git remote repository config {'=' * 20}\")\n","        git_ssh_helper.git_remote_repo_config(   ### Git remote repository config\n","            gh_repo_url     = github_repo_url,\n","            branch_name     = branch_name,    ### Branch to push scaffold\n","            git_push        = False,          ### Skip now, push after syncing files\n","            auto_commit     = auto_commit,\n","            verbose         = verbose\n","        )\n","\n","        # if False:\n","        git_ssh_helper.checkout_or_create_branch(\n","            branch_name     = branch_name,       # Branch to push scaffold\n","            br_remote_name  = br_remote_name,\n","            base_branch     = base_branch,       # Base branch if creating a new branch\n","            verbose         = verbose,\n","        )\n","\n","        if auto_push:\n","\n","            if False:\n","                print(f\"\\n-> Pushing branch '{branch_name}' to remote '{br_remote_name}' ...\")\n","                _, err, code = git_ssh_helper.run_shell_cmd(f\"git push -u {br_remote_name} {branch_name}\", verbose = verbose)\n","                if code == 0: print(f\"-> Branch '{branch_name}' successfully pushed and upstream set!\")\n","                else:         print(f\"-> Push failed! Error: {err}\")\n","\n","            git_ssh_helper.git_commit_push_changes(\n","                commit_msg          = commit_msg,\n","                branch_name         = branch_name,\n","                remote_name         = br_remote_name,\n","                git_push            = auto_push,\n","                verbose             = verbose,\n","                check               = False,\n","                resolve_conflicts   = True,  ### auto handle conflicts\n","            )\n","\n","        print(\"\\n=> Remote && branch configuration completed.\")\n","        return branch_name, br_remote_name, base_branch\n","\n","    #================================================================================================================================\n","    def setup_experiment_path(\n","            model_name,\n","            repo_name,\n","            exper_id    = 1,\n","            base_path   = f\"/content/drive/MyDrive/Colab_Notebooks/Thesis/Code/FEAWAD_Reproducing2/experiments/baseline\"\n","        ):\n","\n","        if not os.path.exists(\"/content/drive/MyDrive\"): connect_google_drive()\n","        if not os.path.exists(base_path): os.makedirs(base_path)\n","\n","        # model_path = f\"{base_path}/{repo_name}/{model_name}/{exper_id}/model\"\n","        model_path   = f\"{base_path}/{repo_name}/{model_name}/model\"\n","        result_path  = f\"{base_path}/{repo_name}/{model_name}/result\"\n","\n","        if not os.path.exists(model_path) : os.makedirs(model_path)\n","        if not os.path.exists(result_path): os.makedirs(result_path)\n","\n","        return model_path, result_path\n","    def writeResults(name, n_samples_trn,  n_outliers, n_samples_test,test_outliers ,test_inliers, avg_AUC_ROC, avg_AUC_PR, std_AUC_ROC,std_AUC_PR, path):\n","        csv_file = open(path, 'a')\n","        row = name + \",\"  + n_samples_trn + ','+n_outliers  + ','+n_samples_test+','+test_outliers+','+test_inliers+','+avg_AUC_ROC+','+avg_AUC_PR+','+std_AUC_ROC+','+std_AUC_PR + \"\\n\"\n","        csv_file.write(row)\n","    def save_experiment(                ### Save experiment configs + checkpoints in Drive\n","            exp_data,\n","            dataset,\n","            model,\n","            variant,\n","            drive_experiments,\n","            checkpoint_path     = None,\n","            uid                 = None\n","        ):\n","\n","        uid      = uid or datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","        save_dir = Path(drive_experiments) / model / dataset / variant / uid\n","        save_dir.mkdir(parents = True, exist_ok = True)\n","\n","        ### Save JSON\n","        save_json = save_dir / \"experiment.json\"\n","        with open(save_json, \"w\") as f: json.dump(exp_data, f, indent = 2)\n","        print(f\"Experiment JSON saved: {save_json}\")\n","\n","        ### Save checkpoint\n","        # if checkpoint_path:\n","            # if not os.path.exists(checkpoint_path): os.mkdir(os.path.dirname(checkpoint_path))\n","            # checkpoint_path = Path(checkpoint_path)\n","        if checkpoint_path and os.path.exists(checkpoint_path):\n","            ckpt_dst = save_dir / Path(checkpoint_path).name\n","            shutil.copy2(checkpoint_path, ckpt_dst)\n","            print(f\"Checkpoint copied: {ckpt_dst}\")\n","        return str(save_dir)\n","######################################################################################################################################\n","\n","## ===================================================================================================================================\n","if True: ##  DRIVE PATHS\n","    _drive_paths_config  = get_drive_helper_paths(\n","        dr_utils_dir_path = \"/content/drive/MyDrive/MSc_AAiT/project_setup_helper/utils\",\n","        path_configs_file = \"drive_path_configs.json\"\n","    )\n","\n","## ===================================================================================================================================\n","if True: ##  IMPORT HELPERS\n","\n","    _ = drive_setup_helper_syspath(dr_setup_helper_path = _drive_paths_config.get('helpers_path'))  ## SYS.PATHS\n","\n","    import utils.project_env as m_proj_env\n","    importlib.reload(m_proj_env)\n","\n","    import utils.project_setup_utils as m_proj_setup_utils\n","    importlib.reload(m_proj_setup_utils)\n","\n","    import utils.git_ssh_utils as m_git_ssh_tools\n","    importlib.reload(m_git_ssh_tools)\n","\n","    assert m_proj_env.COLAB_HOME_PATH is not None, \"proj_configs.COLAB_HOME_PATH is not set. Check .env or load_dotenv path.\"\n","    print(f\"\\nproj_configs.COLAB_HOME_PATH: {m_proj_env.COLAB_HOME_PATH}\")\n","\n","## ===================================================================================================================================\n","if True: ## VARIABLES  (GLOBAL)\n","\n","    m_current_exper_nbook_dir = '2_comparisons'\n","    m_current_exper_name      = 'feature_ae_loss_scorer'\n","    m_current_nbook_subpath   = os.path.join('notebooks', m_current_exper_nbook_dir, f\"{m_current_exper_name}.ipynb\"  )  ## 'notebooks/2_comparisons/feature_ae_loss_scorer.ipynb'\n","    ## /content/drive/MyDrive/MSc_AAiT/experiments/ids-msc-thesis/notebooks/2_comparisons/feature_ae_loss_scorer.ipynb\n","\n","    m_drive_paths_json  = _drive_paths_config\n","    m_drive_repo_path   = os.path.join(m_drive_paths_json['thesis_proj_root_path'], 'experiments', m_proj_env.GITHUB_REPO_NAME)\n","    m_colab_repo_path   = os.path.join(m_proj_env.COLAB_HOME_PATH, m_proj_env.GITHUB_REPO_NAME)         ## Path to the cloned GitHub repo in Colab\n","\n","    m_drive_exper_nb_path = os.path.join(m_drive_repo_path, m_current_nbook_subpath)\n","    m_colab_exper_nb_path = os.path.join(m_colab_repo_path, m_current_nbook_subpath)\n","\n","    ## GIT\n","    m_branch_name    = m_current_exper_name\n","    m_base_branch    = \"main\"\n","    m_br_remote_name = \"origin\"\n"],"metadata":{"id":"RIz4PQjHhJyy","executionInfo":{"status":"ok","timestamp":1759184527352,"user_tz":-180,"elapsed":3055,"user":{"displayName":"zee abate","userId":"01001629947511882888"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fd18a842-1a97-4c38-ad9f-50f6daa839b5"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Util modules path '/content/drive/MyDrive/MSc_AAiT/project_setup_helper' added to sys.path\n","\n","DRIVE_PROJ_PATH in 'project_setup_env.py': '/content/drive/MyDrive/MSc_AAiT/experiments/ids_msc_thesis'\n","\n","DRIVE_PROJ_PATH in 'project_setup_env.py': '/content/drive/MyDrive/MSc_AAiT/experiments/ids_msc_thesis'\n","\n","proj_configs.COLAB_HOME_PATH: /content\n"]}],"id":"RIz4PQjHhJyy"},{"cell_type":"markdown","source":["### `FeaWAD Dataset Utils`"],"metadata":{"id":"opsxUCowPCEb"},"id":"opsxUCowPCEb"},{"cell_type":"code","source":["# %%writefile feawad_loader.py\n","\n","# feawad_loader.py\n","import csv\n","import urllib.request\n","import requests\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","#=================================================================================================================================================\n","def check_remote_file(url):\n","    try:\n","        response = requests.head(url)\n","        return response.status_code == 200\n","    except requests.RequestException as e:\n","        print(f\"Error checking URL: {e}\")\n","        return False\n","def get_weakly_supervised_dataset_by_feawad(data_params = {'data_dim' : 122}):\n","\n","    ### Default\n","    # feawad_repo_name = \"yj-zhou/Feature_Encoding_with_AutoEncoders_for_Weakly-supervised_Anomaly_Detection\"\n","    # feawad_repo_url  = \"https://github.com/yj-zhou/Feature_Encoding_with_AutoEncoders_for_Weakly-supervised_Anomaly_Detection\"\n","\n","    feawad_data_path  = \"https://raw.githubusercontent.com/yj-zhou/Feature_Encoding_with_AutoEncoders_for_Weakly-supervised_Anomaly_Detection/main/dataset/\"\n","    # feawad_data_url = \"https://raw.githubusercontent.com/yj-zhou/Feature_Encoding_with_AutoEncoders_for_Weakly-supervised_Anomaly_Detection/main/dataset/nslkdd_normalization.csv\"\n","\n","    # repo_name     = data_params.get('repo_name',   feawad_repo_name)\n","    # repo_url      = data_params.get('repo_url',    feawad_repo_url)\n","    repo_data_path  = data_params.get('repo_data_path', feawad_data_path)\n","    data_name       = data_params.get('data_name', \"nslkdd_normalization\").strip()\n","    data_ext        = data_params.get('data_ext', 'csv')\n","    local_data_path = data_params.get('local_data_path', './data/')\n","\n","    data_local_file = local_data_path + data_name + '.' + data_ext\n","    data_repo_file  = repo_data_path  + data_name + '.' + data_ext\n","\n","    if not os.path.isfile(data_local_file):\n","        print(f\"\\nDataset file is not found at local path: '{data_local_file}', try to downloading......\\n\")\n","        # if os.path.isfile(data_repo_file):\n","        if check_remote_file(data_repo_file):\n","            urllib.request.urlretrieve(data_repo_file, data_local_file)\n","            # Check again\n","            if not os.path.isfile(data_local_file):\n","                raise ValueError(f\"\\nDataset file is not found at: \\nlocal path: {data_local_file} & at \\nremote url: {data_repo_file}\")\n","        else: raise ValueError(f\"\\nDataset file is not found at remote repo url: '{data_repo_file}'\")\n","    else:\n","        print(f\"\\n'{data_name}' dataset found at local path: '{data_local_file}'.\")\n","\n","    data_dim        = data_params.get('data_dim', 122)\n","    test_size       = data_params.get('test_size', 0.2)\n","    random_seed     = data_params.get('random_seed', 42)\n","    cont_rate       = data_params.get('cont_rate', 0.02)\n","    known_outliers  = data_params.get('known_outliers', 30)\n","    verbose         = data_params.get('verbose', 1)\n","\n","    def _dataLoading(path, byte_num):\n","        # loading data\n","        x       = []\n","        labels  = []\n","\n","        with (open(path,'r')) as data_from:\n","            csv_reader = csv.reader(data_from)\n","            for i in csv_reader:\n","                x.append(i[0:byte_num])\n","                labels.append(i[byte_num])\n","\n","        for i in range(len(x)):\n","            for j in range(byte_num):\n","                x[i][j] = float(x[i][j])\n","        for i in range(len(labels)):\n","            labels[i] = float(labels[i])\n","\n","        x       = np.array(x)\n","        labels  = np.array(labels)\n","\n","        return x, labels;\n","    def _inject_noise(seed, n_out, random_seed):\n","        '''\n","        add anomalies to training data to replicate anomaly contaminated data sets.\n","        we randomly swape 5% features of anomalies to avoid duplicate contaminated anomalies.\n","        this is for dense data\n","        '''\n","        # seed  = Outlier, in loaded set but before split, i.e. 61,000 (gues)\n","        # n_out = n_noise = x_normal * conta_rate / 1-conta_rate = 1166\n","        # 'n_swap_feat'=6, when 'swap_ratio'=0.05 & 'dim'=122\n","        # 'swap_feats' is selected index, e.g. [18 45 47 89  4 40]\n","\n","        rng           = np.random.RandomState(random_seed)\n","        n_sample, dim = seed.shape\n","        swap_ratio    = 0.05\n","        n_swap_feat   = int(swap_ratio * dim)\n","        noise         = np.empty((n_out, dim))\n","\n","        for i in np.arange(n_out):\n","            outlier_idx = rng.choice(n_sample, 2, replace = False)\n","            o1 = seed[outlier_idx[0]] # ------------------------------------> Row Selection\n","            o2 = seed[outlier_idx[1]] # ------------------------------------>    >>\n","            swap_feats = rng.choice(dim, n_swap_feat, replace = False)\n","            noise[i] = o1.copy()\n","            noise[i, swap_feats] = o2[swap_feats]\n","        return noise\n","\n","    x, labels = _dataLoading(data_local_file, byte_num = data_dim)\n","\n","    if verbose: # [Loaded Dataset]\n","        print(f\"\\n[Loaded Dataset]\")\n","        print(f\" - Name    : {data_name}\")\n","        print(f\" - x       : {x.shape}\")\n","        print(f\" - labels  : {labels.shape}\")\n","        print(f\" - Normal  : {len(x[labels == 0])}\")\n","        print(f\" - Outlier : {len(x[labels == 1])}\")\n","\n","    outlier_indices = np.where(labels == 1)[0]\n","    outliers        = x[outlier_indices]\n","    n_outliers_org  = outliers.shape[0]\n","\n","    # Per Runs\n","    train_x, test_x, train_label, test_label = train_test_split(x, labels, test_size = test_size, random_state = random_seed, stratify = labels)\n","\n","    if data_dim != train_x.shape[1]:\n","        raise ValueError(f\"\\n[After Split] Invalid input dimension {data_dim} args, current dataset dimension is {train_x.shape[1]}!\")\n","\n","    rng             = np.random.RandomState(random_seed)\n","    outlier_indices = np.where(train_label == 1)[0]\n","    n_outliers      = len(outlier_indices)\n","    inlier_indices  = np.where(train_label == 0)[0]\n","    n_inliers       = len(inlier_indices)\n","    n_noise         = int(n_inliers * cont_rate / (1. - cont_rate))\n","\n","    if verbose: # [Splited Info]\n","        print(f\"\\n[After Datasets Splited]:\\n\")\n","        print(f\" Train:\")\n","        print(f\" - train_x     : {train_x.shape}\")\n","        print(f\" - train_label : {train_label.shape}\")\n","        print(f\" - Normal      : {len(train_x[train_label == 0])}\")\n","        print(f\" - Outlier     : {len(train_x[train_label == 1])}\")\n","        print(f\" Test:\")\n","        print(f\" - test_x      : {test_x.shape}\")\n","        print(f\" - test_label  : {test_label.shape}\")\n","        print(f\" - Normal      : {len(test_x[test_label == 0])}\")\n","        print(f\" - Outlier     : {len(test_x[test_label == 1])}\")\n","    if verbose: # [Weakly Supervised Config Info]\n","        print(f\"\\n{'-' * 110}\\n\")\n","\n","        print(f\"[Weakly Supervised Setting]:\\n\")\n","        print(f\" Training Dataset With:\")\n","        print(f\" - Outliers : Limited (known size & Identified)\")\n","        print(f\" - Normal   : Noisy   (known size but Unidentified)\")\n","        print(f\" Config:\")\n","        print(f\" - 1. Known Outliers Allowed   : {known_outliers}\")\n","        print(f\" - 2. Noise Contamination Rate : {cont_rate} ({int(cont_rate * 100)}%)\")\n","\n","        print(f\"\\n{'-' * 50}\\n\")\n","\n","        print(f\" Before Outliers Removed (Remove outliers if number of outliers in dataset is exceeds allowed-known-outliers):\")\n","        print(f\" - Normal  : {len(train_x[train_label == 0])}\")\n","        print(f\" - Outlier : {len(train_x[train_label == 1])}\")\n","        print(f\" - Total   : {train_x.shape[0]}\")\n","        print(f\"   {'-' * 28}\")\n","        print(f\" - Outliers to Remove : {n_outliers - known_outliers} = {n_outliers} - {known_outliers} ----> (n_outliers - n_known_outliers)\\n\")\n","\n","    if n_outliers > known_outliers:\n","        mn          = n_outliers - known_outliers\n","        remove_idx  = rng.choice(outlier_indices, mn, replace = False)\n","        train_x     = np.delete(train_x,     remove_idx, axis = 0)\n","        train_label = np.delete(train_label, remove_idx, axis = 0)\n","    else: print(f\"\\n - [Info-Outliers] Number of outliers are NOT GREATER THAN from known outliers.\")\n","\n","    if verbose: # [After Outliers Removed]\n","        print(f\" After Outliers Removed:\")\n","        print(f\" - Normal  : {len(train_x[train_label == 0])}\")\n","        print(f\" - Outlier : {len(train_x[train_label == 1])}\")\n","        print(f\" - Total   : {train_x.shape[0]}\")\n","        print(f\"   {'-' * 28}\")\n","        print(f\" - Outliers Removed : {n_outliers - known_outliers}\")\n","    if verbose: # [Noise Adding]\n","        print(f\"\\n{'-' * 100}\\n\")\n","        print(f\" Before Noise Added:\")\n","        print(f\" - Normal (Clean)   : {len(train_x[train_label == 0])}\")\n","        print(f\" - Outlier          : {len(train_x[train_label == 1])}\")\n","        print(f\" - Total            : {train_x.shape[0]}\")\n","        print(f\"   {'-' * 28}\")\n","        print(f\" - Noises to Inject : {n_noise} -----------> [Computed: x_normal * cont_rate / (1-cont_rate)]\\n\")\n","\n","    noises      = _inject_noise(outliers, n_noise, random_seed)\n","    train_x     = np.append(train_x, noises, axis = 0)\n","    train_label = np.append(train_label, np.zeros((noises.shape[0], 1)))    # Label Noising\n","\n","    if verbose: # [Noise Added]\n","        print(f\" After Noise Added (Generated based on outliers data):\")\n","        print(f\" - Normal (Noisy)  : {len(train_x[train_label == 0])}\")\n","        print(f\" - Outlier         : {len(train_x[train_label == 1])}\")\n","        print(f\" - Total           : {train_x.shape[0]}\")\n","        print(f\"   {'-' * 28}\")\n","        print(f\" - Noises Injected : {n_noise}\")\n","\n","    if data_dim != train_x.shape[1]:\n","        raise ValueError(f\"\\n[Before Training Loop] Invalid input dimension {data_dim} args, current dataset dimension is {train_x.shape[1]}!\")\n","\n","    outlier_indices = np.where(train_label == 1)[0]\n","    inlier_indices  = np.where(train_label == 0)[0]\n","    # train_x_inlier= np.delete(train_x, outlier_indices, axis = 0)   # ???\n","\n","    input_shape   = train_x.shape[1:]\n","    n_samples_trn = train_x.shape[0]\n","    n_outliers    = len(outlier_indices)\n","\n","    n_samples_test       = test_x.shape[0]\n","    test_outlier_indices = np.where(test_label == 1)[0]\n","    test_inlier_indices  = np.where(test_label == 0)[0]\n","\n","    if verbose: # [Processed Info]\n","        print(f\"\\n{'_' * 100}\")\n","        print(f\"\\n[Dataset] All Processed {'*' * 80}\\n\")\n","        print(f\" Train:\")\n","        print(f\" - Mixed   train_y : {train_label.shape}\")\n","        print(f\" - Mixed   train_x : {train_x.shape}\")\n","        print(f\"   {'-' * 28}\")\n","        print(f\" - Normal  train_x : {inlier_indices.shape[0]}\")\n","        print(f\" - Outlier train_x : {outlier_indices.shape[0]}\\n\")\n","        print(f\" Test:\")\n","        print(f\" - Mixed   test_y  : {test_label.shape}\")\n","        print(f\" - Mixed   test_x  : {test_x.shape}\")\n","        print(f\"   {'-' * 28}\")\n","        print(f\" - Normal  test_x  : {test_inlier_indices.shape[0]}\")\n","        print(f\" - Outlier test_x  : {test_outlier_indices.shape[0]}\")\n","\n","    return train_x, train_label, test_x, test_label\n"],"metadata":{"id":"Lnj7tkj9Rqti"},"execution_count":null,"outputs":[],"id":"Lnj7tkj9Rqti"},{"cell_type":"markdown","source":["## **GitHub Setup**"],"metadata":{"id":"TjKgtHcUnWKh"},"id":"TjKgtHcUnWKh"},{"cell_type":"markdown","source":["### `SSH Session`"],"metadata":{"id":"msUwRTR9WlMa"},"id":"msUwRTR9WlMa"},{"cell_type":"code","source":["### Configure SSH & GitHub auth\n","manage_gitssh_colab_github(\n","    project_envs        = m_proj_env,\n","    git_ssh_helper      = m_git_ssh_tools,\n","    start_ssh_session   = True,   ### Start a session with stored key\n","    show_pub_key        = False,  ### Show public key\n","    force_new_keys_gen  = False   ### Regenerate keys\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"SEUZ18bWSGk5","executionInfo":{"status":"ok","timestamp":1759184536992,"user_tz":-180,"elapsed":1281,"user":{"displayName":"zee abate","userId":"01001629947511882888"}},"outputId":"d3b2eed5-1332-40d0-cc54-83467bb8d0dc"},"id":"SEUZ18bWSGk5","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================== Git global config (In colab) ====================\n","\n","[CMD] : git config --global user.name Abate, Zelalem\n","\n","[CODE]  : 0\n","\n","[CMD] : git config --global user.email phatzolo@gmail.com\n","\n","[CODE]  : 0\n","\n","==================== Start new ssh session (colab-github) ====================\n","\n","-> SSH Key-Pair already generated before & found at path: /content/drive/MyDrive/MSc_AAiT/project_setup_helper/id_rsa.\n","\n","-> SSH public key generated before & assumed to be added to GitHub. SSH Key-Pair Path: /content/drive/MyDrive/MSc_AAiT/project_setup_helper/id_rsa\n","\n","-> Setting up ssh session in: /root/.ssh\n","\n","-> Adding GitHub to known_hosts...\n","\n","-> Starting ssh-agent & adding private key...\n","\n","[ERROR]: Command failed (exit 127): ['bash', '-c', '\\n    eval \"$(ssh-agent -s)\"\\n    ssh-add /root/.ssh/id_rsa\\n    ssh -T git@github.com || 0\\n    ']\n","\n","[STDERR]: Identity added: /root/.ssh/id_rsa (phatzolo@gmail.com)\n","Hi zelalemteferi! You've successfully authenticated, but GitHub does not provide shell access.\n","bash: line 4: 0: command not found\n","\n","-> SSH session to gitHub established successfully!!!\n"]}]},{"cell_type":"markdown","source":["### `Clone Repo`"],"metadata":{"id":"9Zzl1xnbfVE7"},"id":"9Zzl1xnbfVE7"},{"cell_type":"code","source":["## GitHub ---> Drive\n","m_github_repo_url = clone_repo_from_github(\n","    m_proj_env,\n","    m_git_ssh_tools,\n","    m_colab_repo_path,  ## Path to the cloned GitHub repo in Colab\n","    verbose             = m_proj_env.VERBOSE,\n","    force_clone         = True\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"rsUgPCCwcdvt","executionInfo":{"status":"ok","timestamp":1759184546008,"user_tz":-180,"elapsed":886,"user":{"displayName":"zee abate","userId":"01001629947511882888"}},"outputId":"b25acb70-d083-403e-87df-898232728241"},"id":"rsUgPCCwcdvt","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=> Repo is not cloned before, procede to cloning ...\n","\n","=> github_repo_url: git@github.com:zelalemteferi/ids-msc-thesis.git\n","\n","==================== Clone the repository (github --> colab) ====================\n","\n","=> Cloning 'ids-msc-thesis' to '/content/ids-msc-thesis'\n","\n","=> Cloning 'ids-msc-thesis' to '/content/ids-msc-thesis'\n","\n","[CMD] : git clone git@github.com:zelalemteferi/ids-msc-thesis.git\n","\n","[STDERR]: Cloning into 'ids-msc-thesis'...\n","\n","[CODE]  : 0\n","\n","-> Git clone is SUCCESSFUL!\n","\n","-> Current dir  : /content/ids-msc-thesis\n","\n","-> Repo contents:\n","\n","=> Cloned repo is git-repo (.git file):\n","total 240\n","drwxr-xr-x  8 root root   4096 Sep 29 22:22 .\n","drwxr-xr-x 11 root root   4096 Sep 29 22:22 ..\n","drwxr-xr-x  2 root root   4096 Sep 29 22:22 branches\n","-rw-r--r--  1 root root    268 Sep 29 22:22 config\n","-rw-r--r--  1 root root     73 Sep 29 22:22 description\n","-rw-r--r--  1 root root     21 Sep 29 22:22 HEAD\n","drwxr-xr-x  2 root root   4096 Sep 29 22:22 hooks\n","-rw-r--r--  1 root root 196030 Sep 29 22:22 index\n","drwxr-xr-x  2 root root   4096 Sep 29 22:22 info\n","drwxr-xr-x  3 root root   4096 Sep 29 22:22 logs\n","drwxr-xr-x  4 root root   4096 Sep 29 22:22 objects\n","-rw-r--r--  1 root root    196 Sep 29 22:22 packed-refs\n","drwxr-xr-x  5 root root   4096 Sep 29 22:22 refs\n","\n","=> Current working directory (cloned repo): /content/ids-msc-thesis\n"]}]},{"cell_type":"markdown","source":["### `Clean Commit`"],"metadata":{"id":"EavxoeJiYCW0"},"id":"EavxoeJiYCW0"},{"cell_type":"code","source":["## BACKUP GITHUB --> COLAB --> DRIVE\n","if True:\n","    # !cp -r /content/ids-msc-thesis /content/drive/MyDrive/MSc_AAiT/scaffold_FIRST_PUSHED_BACKUP2\n","    m_git_ssh_tools.delete_commit_history(\n","        branch_name     = m_branch_name,            ## branch_name (feature_branch) = \"feature_ae_loss_scorer\",\n","        main_branch     = m_base_branch,            ## \"main\",\n","        remote_name     = m_br_remote_name,         ## \"origin\", # DEFAULT\n","        commit_msg      = \"Initial commit (commit history cleaned)\",\n","        backup_main_br  = False,\n","        backup_feat_br  = False,\n","        verbose         = True\n","    )"],"metadata":{"id":"pYBNuvC3orwB","executionInfo":{"status":"ok","timestamp":1759184418334,"user_tz":-180,"elapsed":2091,"user":{"displayName":"zee abate","userId":"01001629947511882888"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ee75287d-6d69-42c1-993a-dd09dd0ea5b7"},"id":"pYBNuvC3orwB","execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[CMD] : git checkout --orphan main_last_commit\n","\n","[STDERR]: Switched to a new branch 'main_last_commit'\n","\n","[CODE]  : 0\n","\n","[CMD] : git add -A\n","\n","[CODE]  : 0\n","\n","[ERROR]: Command failed (exit 2): git commit -m Initial commit (commit history cleaned)\n","\n","[STDERR]: /bin/sh: 1: Syntax error: \"(\" unexpected\n","\n","[ERROR]: Command failed (exit 1): git branch -D main\n","\n","[STDERR]: error: branch 'main' not found.\n","\n","[CMD] : git branch -m main\n","\n","[CODE]  : 0\n","\n","[ERROR]: Command failed (exit 1): git push -f origin main\n","\n","[STDERR]: error: src refspec main does not match any\n","error: failed to push some refs to 'github.com:zelalemteferi/ids-msc-thesis.git'\n","'main' commit history deleted, new created & pushed\n","\n","[CMD] : git push origin --delete feature_ae_loss_scorer\n","\n","[STDERR]: To github.com:zelalemteferi/ids-msc-thesis.git\n"," - [deleted]         feature_ae_loss_scorer\n","\n","[CODE]  : 0\n","Old remote feature branch 'feature_ae_loss_scorer' deleted\n","\n","[ERROR]: Command failed (exit 128): git checkout -b feature_ae_loss_scorer\n","\n","[STDERR]: fatal: A branch named 'feature_ae_loss_scorer' already exists.\n","\n","[CMD] : git push -u origin feature_ae_loss_scorer\n","\n","[STDOUT]: Branch 'feature_ae_loss_scorer' set up to track remote branch 'feature_ae_loss_scorer' from 'origin'.\n","\n","[STDERR]: remote: \n","remote: Create a pull request for 'feature_ae_loss_scorer' on GitHub by visiting:        \n","remote:      https://github.com/zelalemteferi/ids-msc-thesis/pull/new/feature_ae_loss_scorer        \n","remote: \n","To github.com:zelalemteferi/ids-msc-thesis.git\n"," * [new branch]      feature_ae_loss_scorer -> feature_ae_loss_scorer\n","\n","[CODE]  : 0\n","Feature branch 'feature_ae_loss_scorer' recreated from new 'main' branch\n","Repository commit history deleted successfully!\n"]}]},{"cell_type":"code","source":["# !git status\n","# !git branch -a                ## To confirms that branch exists both locally & remotely\n","# !git remote -v                ## To show remote origin configuration\n","# !git remote show origin       ## To show local branch tracks the remote branch correctly\n","# !git log --oneline            ## Check commit history\n","\n","### Check commit history (should be one commit)\n","!git log --oneline\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"poWK3yoORNcN","executionInfo":{"status":"ok","timestamp":1759182932462,"user_tz":-180,"elapsed":57,"user":{"displayName":"zee abate","userId":"01001629947511882888"}},"outputId":"b7be6975-9839-402d-eb1c-2ee5f50a0a42"},"id":"poWK3yoORNcN","execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mc439d74\u001b[m\u001b[33m (\u001b[m\u001b[1;36mHEAD -> \u001b[m\u001b[1;32mfeature_ae_loss_scorer\u001b[m\u001b[33m, \u001b[m\u001b[1;31morigin/feature_ae_loss_scorer\u001b[m\u001b[33m)\u001b[m Push updated experiment nootbook ('feature_ae_loss_scorer')\n","\u001b[33mc89397a\u001b[m Merge branch 'feature_ae_loss_scorer'\n","\u001b[33md4d643f\u001b[m Push updated experiment nootbook ('feature_ae_loss_scorer')\n","\u001b[33mc9a4cff\u001b[m Push updated experiment nootbook ('feature_ae_loss_scorer')\n","\u001b[33m9841c51\u001b[m Push updated experiment nootbook ('feature_ae_loss_scorer')\n","\u001b[33m73bfdc8\u001b[m Push updated experiment nootbook ('feature_ae_loss_scorer')\n","\u001b[33m8d6d905\u001b[m Update experiment notebook feature_ae_loss_scorer\n","\u001b[33m53d55a5\u001b[m Push updated experiment nootbook ('feature_ae_loss_scorer')\n","\u001b[33mfe59c00\u001b[m Push updated experiment nootbook ('feature_ae_loss_scorer')\n","\u001b[33m3373dc8\u001b[m Add scaffold from Drive\n","\u001b[33mfab0aa4\u001b[m Initial commit\n"]}]},{"cell_type":"code","source":["!git branch -a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a1MBFUrQMKOs","executionInfo":{"status":"ok","timestamp":1759184434238,"user_tz":-180,"elapsed":55,"user":{"displayName":"zee abate","userId":"01001629947511882888"}},"outputId":"fdef07b5-139c-493b-caaa-ac48cf0f3164"},"id":"a1MBFUrQMKOs","execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["  feature_ae_loss_scorer\u001b[m\n","  \u001b[31mremotes/origin/HEAD\u001b[m -> origin/main\n","  \u001b[31mremotes/origin/feature_ae_loss_scorer\u001b[m\n","  \u001b[31mremotes/origin/main\u001b[m\n"]}]},{"cell_type":"code","source":["!git log --oneline\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"94iEcdHXkCff","executionInfo":{"status":"ok","timestamp":1759184443942,"user_tz":-180,"elapsed":95,"user":{"displayName":"zee abate","userId":"01001629947511882888"}},"outputId":"050533ed-3327-47c9-fe9e-da6f131085ef"},"id":"94iEcdHXkCff","execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: your current branch 'main' does not have any commits yet\n"]}]},{"cell_type":"markdown","source":["### `Git-Remote & Branch Configs`"],"metadata":{"id":"GXoooYlY5pDG"},"id":"GXoooYlY5pDG"},{"cell_type":"code","source":["m_branch_name, m_br_remote_name, m_base_branch = git_remote_and_branch_config(\n","    project_envs        = m_proj_env,\n","    git_ssh_helper      = m_git_ssh_tools,\n","    github_repo_url     = m_github_repo_url,\n","    branch_name         = m_branch_name,            ## m_current_exper_name == \"feature_ae_loss_scorer\",\n","    br_remote_name      = m_br_remote_name,         ## \"origin\",\n","    base_branch         = m_base_branch,            ## \"main\",\n","    auto_commit         = True,\n","    verbose             = True,\n","    commit_msg          = \"Git-Remote & Branch Configs\"\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"GsoTpFpeKGxL","executionInfo":{"status":"ok","timestamp":1759184565821,"user_tz":-180,"elapsed":795,"user":{"displayName":"zee abate","userId":"01001629947511882888"}},"outputId":"9a5d2269-2f39-46a3-c469-6e8378c79d14"},"id":"GsoTpFpeKGxL","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================== Git remote repository config ====================\n","\n","==================================================\n","Configuring Git remote for: git@github.com:zelalemteferi/ids-msc-thesis.git\n","==================================================\n","\n","[CMD] : git checkout feature_ae_loss_scorer\n","\n","[STDOUT]: Branch 'feature_ae_loss_scorer' set up to track remote branch 'feature_ae_loss_scorer' from 'origin'.\n","\n","[STDERR]: Switched to a new branch 'feature_ae_loss_scorer'\n","\n","[CODE]  : 0\n","-> Updating/Resetting existing remote URL\n","\n","[CMD] : git remote set-url origin git@github.com:zelalemteferi/ids-msc-thesis.git\n","\n","[CODE]  : 0\n","-> Auto git-committed...\n","status\n","\n","-> *** No changes to git commit & push ***\n","\n","=> Verify remote configs:\n","\n","[CMD] : git remote -v\n","\n","[STDOUT]: origin\tgit@github.com:zelalemteferi/ids-msc-thesis.git (fetch)\n","origin\tgit@github.com:zelalemteferi/ids-msc-thesis.git (push)\n","\n","[CODE]  : 0\n","\n","=> Current branch status:\n","\n","[CMD] : git status -sb\n","\n","[STDOUT]: ## feature_ae_loss_scorer...origin/feature_ae_loss_scorer\n","\n","[CODE]  : 0\n","\n","==================================================\n","REMOTE CONFIGURATION COMPLETED SUCCESSFULLY!\n","==================================================\n","\n","Fetching all remote branches...\n","\n","Local branches : ['feature_ae_loss_scorer', 'main'] \n","Remote branches: ['HEAD -> origin/main', 'feature_ae_loss_scorer', 'main']\n","\n","Branch 'feature_ae_loss_scorer' exists locally. Checking out...\n","\n","Current checked-out branch: feature_ae_loss_scorer\n","status\n","\n","-> *** No changes to git commit & push ***\n","\n","=> Remote && branch configuration completed.\n"]}]},{"cell_type":"markdown","source":["### `.... Check Git`"],"metadata":{"id":"JsiVxllmMEo3"},"id":"JsiVxllmMEo3"},{"cell_type":"code","source":["# !git status\n","# !git branch -a                ## To confirms that branch exists both locally & remotely\n","# !git remote -v                ## To show remote origin configuration\n","# !git remote show origin       ## To show local branch tracks the remote branch correctly\n","# !git log --oneline            ## Check commit history"],"metadata":{"id":"kmGZcZxOWPqy"},"id":"kmGZcZxOWPqy","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git remote show origin"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Le8l3qDx030L","executionInfo":{"status":"ok","timestamp":1759184585279,"user_tz":-180,"elapsed":394,"user":{"displayName":"zee abate","userId":"01001629947511882888"}},"outputId":"5dbb6923-1a94-4e47-c2b5-cc25b992ae08"},"id":"Le8l3qDx030L","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["* remote origin\n","  Fetch URL: git@github.com:zelalemteferi/ids-msc-thesis.git\n","  Push  URL: git@github.com:zelalemteferi/ids-msc-thesis.git\n","  HEAD branch: main\n","  Remote branches:\n","    feature_ae_loss_scorer tracked\n","    main                   tracked\n","  Local branches configured for 'git pull':\n","    feature_ae_loss_scorer merges with remote feature_ae_loss_scorer\n","    main                   merges with remote main\n","  Local refs configured for 'git push':\n","    feature_ae_loss_scorer pushes to feature_ae_loss_scorer (up to date)\n","    main                   pushes to main                   (up to date)\n"]}]},{"cell_type":"code","source":["!git branch -a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M9_CR2L5ku-r","executionInfo":{"status":"ok","timestamp":1759184615623,"user_tz":-180,"elapsed":120,"user":{"displayName":"zee abate","userId":"01001629947511882888"}},"outputId":"8f98d0a4-93a6-4ab9-a56c-68490ca37921"},"id":"M9_CR2L5ku-r","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["* \u001b[32mfeature_ae_loss_scorer\u001b[m\n","  main\u001b[m\n","  \u001b[31mremotes/origin/HEAD\u001b[m -> origin/main\n","  \u001b[31mremotes/origin/feature_ae_loss_scorer\u001b[m\n","  \u001b[31mremotes/origin/main\u001b[m\n"]}]},{"cell_type":"code","source":["!git log --oneline"],"metadata":{"id":"9X8VWrOHkzJK","executionInfo":{"status":"ok","timestamp":1759184632536,"user_tz":-180,"elapsed":117,"user":{"displayName":"zee abate","userId":"01001629947511882888"}},"outputId":"3c5d3aa8-acff-452a-97e8-8a9c97f1e911","colab":{"base_uri":"https://localhost:8080/"}},"id":"9X8VWrOHkzJK","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mc439d74\u001b[m\u001b[33m (\u001b[m\u001b[1;36mHEAD -> \u001b[m\u001b[1;32mfeature_ae_loss_scorer\u001b[m\u001b[33m, \u001b[m\u001b[1;31morigin/feature_ae_loss_scorer\u001b[m\u001b[33m)\u001b[m Push updated experiment nootbook ('feature_ae_loss_scorer')\n","\u001b[33mc89397a\u001b[m Merge branch 'feature_ae_loss_scorer'\n","\u001b[33md4d643f\u001b[m Push updated experiment nootbook ('feature_ae_loss_scorer')\n","\u001b[33mc9a4cff\u001b[m Push updated experiment nootbook ('feature_ae_loss_scorer')\n","\u001b[33m9841c51\u001b[m Push updated experiment nootbook ('feature_ae_loss_scorer')\n","\u001b[33m73bfdc8\u001b[m Push updated experiment nootbook ('feature_ae_loss_scorer')\n","\u001b[33m8d6d905\u001b[m Update experiment notebook feature_ae_loss_scorer\n","\u001b[33m53d55a5\u001b[m Push updated experiment nootbook ('feature_ae_loss_scorer')\n","\u001b[33mfe59c00\u001b[m Push updated experiment nootbook ('feature_ae_loss_scorer')\n","\u001b[33m3373dc8\u001b[m Add scaffold from Drive\n","\u001b[33mfab0aa4\u001b[m Initial commit\n"]}]},{"cell_type":"markdown","source":["### `Commit & Push (This Nootebook)`"],"metadata":{"id":"stpfz0O46UHE"},"id":"stpfz0O46UHE"},{"cell_type":"code","source":["## ********************** REMEMBER  (SAVE CHANGES (THIS NOTEBOOK)) ******************************\n","\n","nb_updated = False\n","\n","## 1. COPY: DRIVE --> COLAB\n","if not nb_updated:\n","    shutil.copy2(m_drive_exper_nb_path, m_colab_exper_nb_path)\n","    print(f\"Copied {m_drive_exper_nb_path} ---> {m_colab_exper_nb_path}\")\n","    nb_updated = True"],"metadata":{"id":"3OL568c5hzSb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759182581718,"user_tz":-180,"elapsed":706,"user":{"displayName":"zee abate","userId":"01001629947511882888"}},"outputId":"348c54f5-6184-4dff-9fd7-3c1656f2e07d"},"id":"3OL568c5hzSb","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Copied /content/drive/MyDrive/MSc_AAiT/experiments/ids-msc-thesis/notebooks/2_comparisons/feature_ae_loss_scorer.ipynb ---> /content/ids-msc-thesis/notebooks/2_comparisons/feature_ae_loss_scorer.ipynb\n"]}]},{"cell_type":"code","source":["## 2. COMMIT + PUSH\n","if nb_updated:\n","    m_git_ssh_tools.git_commit_push_changes(\n","        commit_msg  = f\"Push updated experiment nootbook ('{m_branch_name}')\",\n","        branch_name = m_branch_name,        ## 'main',\n","        remote_name = m_br_remote_name,     ## \"origin\",\n","        git_push    = True,\n","        verbose     = False\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4dc3qonQfZDP","executionInfo":{"status":"ok","timestamp":1759182654566,"user_tz":-180,"elapsed":1089,"user":{"displayName":"zee abate","userId":"01001629947511882888"}},"outputId":"53914ea7-72fa-4979-ea0e-10b93d62147c"},"id":"4dc3qonQfZDP","execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["status\n","M notebooks/2_comparisons/feature_ae_loss_scorer.ipynb\n","-> Changes pushed to origin/feature_ae_loss_scorer\n"]}]},{"cell_type":"markdown","source":["### `Final Merge & Push`"],"metadata":{"id":"DkJiDimZ7KWT"},"id":"DkJiDimZ7KWT"},{"cell_type":"code","source":["m_git_ssh_tools.merge_feature_branch(\n","    feature_branch  = m_branch_name,        ## m_branch_name == \"feature_ae_loss_scorer\"\n","    main_branch     = m_base_branch,        ## \"main\",\n","    remote_name     = m_br_remote_name,     ## \"origin\",\n","    use_rebase      = True,\n","    verbose         = True,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Bk3pe-P_Jdr","executionInfo":{"status":"ok","timestamp":1759182711696,"user_tz":-180,"elapsed":5834,"user":{"displayName":"zee abate","userId":"01001629947511882888"}},"outputId":"f6d31101-680f-4006-e073-df6db281cbae","collapsed":true},"id":"3Bk3pe-P_Jdr","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Using merge strategy: 'rebase', merging: feature_ae_loss_scorer ----> main\n","-> *** No local changes to save (stash) ***\n","\n","[CMD] : git fetch origin\n","\n","[CODE]  : 0\n","\n","[CMD] : git checkout main\n","\n","[STDOUT]: Your branch is up to date with 'origin/main'.\n","\n","[STDERR]: Switched to branch 'main'\n","\n","[CODE]  : 0\n","\n","[CMD] : git pull origin main\n","\n","[STDOUT]: Already up to date.\n","\n","[STDERR]: From github.com:zelalemteferi/ids-msc-thesis\n"," * branch            main       -> FETCH_HEAD\n","\n","[CODE]  : 0\n","\n","[CMD] : git checkout feature_ae_loss_scorer\n","\n","[STDOUT]: Your branch is up to date with 'origin/feature_ae_loss_scorer'.\n","\n","[STDERR]: Switched to branch 'feature_ae_loss_scorer'\n","\n","[CODE]  : 0\n","\n","[CMD] : git pull origin feature_ae_loss_scorer\n","\n","[STDOUT]: Already up to date.\n","\n","[STDERR]: From github.com:zelalemteferi/ids-msc-thesis\n"," * branch            feature_ae_loss_scorer -> FETCH_HEAD\n","\n","[CODE]  : 0\n","Rebasing feature branch onto main ...\n","\n","[CMD] : git rebase main\n","\n","[STDERR]: Rebasing (1/1)\n","\n","\u001b[KSuccessfully rebased and updated refs/heads/feature_ae_loss_scorer.\n","\n","[CODE]  : 0\n","\n","[CMD] : git checkout main\n","\n","[STDOUT]: Your branch is up to date with 'origin/main'.\n","\n","[STDERR]: Switched to branch 'main'\n","\n","[CODE]  : 0\n","\n","[CMD] : git merge feature_ae_loss_scorer --no-ff\n","\n","[STDOUT]: Merge made by the 'ort' strategy.\n"," notebooks/2_comparisons/feature_ae_loss_scorer.ipynb | 2 +-\n"," 1 file changed, 1 insertion(+), 1 deletion(-)\n","\n","[CODE]  : 0\n","\n","[CMD] : git push origin main\n","\n","[STDERR]: To github.com:zelalemteferi/ids-msc-thesis.git\n","   c89397a..612e070  main -> main\n","\n","[CODE]  : 0\n","\n","[CMD] : git checkout feature_ae_loss_scorer\n","\n","[STDOUT]: Your branch and 'origin/feature_ae_loss_scorer' have diverged,\n","and have 2 and 1 different commits each, respectively.\n","  (use \"git pull\" to merge the remote branch into yours)\n","\n","[STDERR]: Switched to branch 'feature_ae_loss_scorer'\n","\n","[CODE]  : 0\n","\n","[CMD] : git push origin feature_ae_loss_scorer --force-with-lease\n","\n","[STDERR]: To github.com:zelalemteferi/ids-msc-thesis.git\n"," + 5b94162...c439d74 feature_ae_loss_scorer -> feature_ae_loss_scorer (forced update)\n","\n","[CODE]  : 0\n","\n","[CMD] : git push origin main\n","\n","[STDERR]: Everything up-to-date\n","\n","[CODE]  : 0\n","Merge completed successfully!\n"]}]},{"cell_type":"markdown","source":["# ============== `Experiments` ======================================"],"metadata":{"id":"iX6NkP-Bvcpo"},"id":"iX6NkP-Bvcpo"},{"cell_type":"code","source":[],"metadata":{"id":"P7REEDIlZOr5"},"id":"P7REEDIlZOr5","execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["ezpdQmpDmtHb","ScCyV6Gx_3rs","cEawIvZLjm1r","DIQPM6MeURkg","eyQtkTTXdV-5","VoJnHp4fnRSw","D7wzqeNGi6Yr","IGtGRqUdnRj_","opsxUCowPCEb","msUwRTR9WlMa","GXoooYlY5pDG","JsiVxllmMEo3","stpfz0O46UHE","DkJiDimZ7KWT","iX6NkP-Bvcpo"]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}